{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PROBLEM STATEMENT`\n",
    "\n",
    "The objective is to create a prediction model that can reliably anticipate real estate prices or property values based on a range of characteristics, including cost, house size in square footage, number of bathrooms, size and presence of a basement, number of floors and more. The objective is to support purchasers, vendors, and real estate agents in making knowledgeable choices about real estate transactions.\n",
    " \n",
    " \n",
    "## `HYPOTHESIS GENERATION`\n",
    "\n",
    "In our real estate analysis, we consider several hypotheses impacting property value. First, there’s a strong positive correlation between a house’s square footage and its value. Larger living areas tend to fetch higher prices. Second, the number of bathrooms positively influences a home’s value. Properties with more bathrooms are more convenient and appealing, commanding higher prices. Third, multi-level properties may be worth more due to increased living space and potential views. Fourth, well-maintained homes are likely to cost more than those needing repairs. Fifth, renovations enhance a property’s value. Sixth, basements positively impact property value. Finally, newer properties tend to have higher values due to modern amenities and desirability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits\n",
    "import matplotlib.ticker as mticker\n",
    "%matplotlib inline\n",
    "\n",
    "# For handling multiple files\n",
    "from glob import glob\n",
    "\n",
    "# for cat features\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "# For interactive dashboard\n",
    "from ipywidgets import Dropdown, FloatSlider, IntSlider, interact\n",
    "\n",
    "from sklearn.impute import SimpleImputer # Handling missing values\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Disable the SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any `null values`, so we dont need to remove any data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the summary statistics of the dataset. We can see our means and min and max values for each. \n",
    "\n",
    "We also see that some columns like the `price` and the `square_foot` columns have a `high Standard Deviation`, which tells us that our `features vary widely`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(numeric_only=True),\n",
    "            cmap = 'BrBG',\n",
    "            fmt = '.2f',\n",
    "            linewidths = 2,\n",
    "            annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `heatmap` is like a correlation matrix. It helps us see which features correlate with which.\n",
    "\n",
    "In the above we firstly look at the `Price` column, we notice that there aren't many strongly correlated features. However we do see that `bathrooms` & `sqft_living` have some positive correlation, so it will be interesting to see how they play out.\n",
    "\n",
    "Looking at the data as a whole we see some interesting points:\n",
    "- `sqft_living` & `sqft_above`, have a `high positive correlation`, which makes sense, as you would expect that the bigger the living space, the higher the \"above\" section would be comapred to the \"basement\". We can see this is true by the `slight positive correlation` with `sqft_basement`\n",
    "- We also see `condition` & `yr_built` have a `negative correlation`, showing that older houses have a worse condition which makes sense\n",
    "- `waterfront` and `view` have a positive correlation\n",
    "\n",
    "#### So we have some good information, but not all of these points will help us predict house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.sqft_living, df.price)\n",
    "plt.title(\"Price vs sqft_living\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `price` starts `increasing as the sqft increases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms help us understand the distribution of data a lot better. It is interesting to note how the data looks:\n",
    "- `bedrooms` seems to be the only feature with a normal bell curve\n",
    "- All the `sqft_` graphs seem to be skewed left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"city\"].value_counts().plot(kind='bar')\n",
    "plt.title(\"No. of houses per city\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Count\")\n",
    "sns.despine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diagram above we can see that `Seattle` has the most amount of houses by far. But will this mean they have the `highest average price`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"city\")[\"price\"].mean().plot(kind='bar')\n",
    "plt.title(\"Average Price of Houses per City\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although `Seattle` has the highest count it is on the `lower side` in terms of `ave_price`. This could indicate `Seattle` is a densely populated area due to having cheaper housing, but also has oppurtunities.\n",
    "\n",
    "### We now have a better understanding of our data, we can proceed with Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Off the bat, there are some basic changes we can make:\n",
    "\n",
    "- `date` needs to be changed to `datetime`\n",
    "- We also saw in the beginning that there was data in the dataset in the `price` column that was `0`.\n",
    "This means that there are outliers, so we can get rid of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for cardinality\n",
    "\n",
    "- cardinality is a measure of the uniqueness of data in a column\n",
    "- So it is important to remove features with very high, or low cardinality.\n",
    "- We can check that with some code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = df.select_dtypes(\"object\").nunique()\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `5 object columns`\n",
    "- `date` will not help us in prediction, as it is not a date of any relevant time in the houses' lifespan\n",
    "- `street` has a lot of unique data, so it can be dropped\n",
    "- `country` is 1, so it goes. And we want to use `city` in our prediction, so `statezip` can also go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "It can be very useful to create more features by using other features:\n",
    "\n",
    "- ratio of bathrooms and bedrooms\n",
    "- price per sqft\n",
    "- bathroom & bedroom interactions (multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We going to create a `function` that will help summarise all our preperation into 1 block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepared():\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "   \n",
    "    # Convert 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])  \n",
    "   \n",
    "    # Filter out outliers in the 'price' column\n",
    "    df = df[(df['price'] >= df['price'].quantile(0.1)) & (df['price'] <= df['price'].quantile(0.9))]\n",
    "   \n",
    "    # Feature Engineering: Calculate the ratio of Bedrooms to Bathrooms\n",
    "    df['bedrooms_to_bathrooms_ratio'] = df['bedrooms'] / df['bathrooms']\n",
    "     \n",
    "    # Feature Engineering: Calculate Price per Square Foot\n",
    "    df['price_per_sqft'] = df['price'] / df['sqft_living']\n",
    "   \n",
    "    # Feature Engineering: Create Interaction Features (e.g., 'bedrooms' * 'bathrooms')\n",
    "    df['bedrooms_bathrooms_interaction'] = df['bedrooms'] * df['bathrooms']\n",
    " \n",
    "    # Drop 'country' and 'statezip' columns\n",
    "    df = df.drop(columns=[\"country\", \"statezip\"])\n",
    " \n",
    "    # Drop additional features not needed for analysis\n",
    "    df = df.drop(columns=['sqft_above', 'sqft_basement', 'yr_renovated', 'condition', 'yr_built','date','street','city','sqft_lot'])\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(data_prepared().corr(numeric_only=True),\n",
    "            cmap = 'YlGnBu',\n",
    "            fmt = '.2f',\n",
    "            linewidths = 2,\n",
    "            annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our `method` we can observe some of the changes above:\n",
    "\n",
    "- `sqft_living & price_per_sqft` is still our highest correlating variables with `price`\n",
    "- All the new features, have `high correlation` with `bathroom & bedroom`. Which is to be expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "### We will first of start with `Random Forest Reggresion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_prepared().drop(columns=['price'])  # Features\n",
    "y = data_prepared()['price']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the Random Forest Regressor\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_score = rf_reg.score(X_test, y_test)\n",
    "print(\"Random Forest Regressor Score:\", rf_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of `99%` seems very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = make_pipeline(\n",
    "\n",
    "    # Imputation\n",
    "    SimpleImputer(),\n",
    "\n",
    "    # build model\n",
    "    RandomForestRegressor(\n",
    "        random_state=42)\n",
    "    )\n",
    "\n",
    "# fit the model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the train data\n",
    "y_pred_training = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# Compute MAE\n",
    "print(f\"Training MAE:${round(mean_absolute_error(y_train, y_pred_training),2)}\")\n",
    "print(f\"Test data MAE:${round(mean_absolute_error(y_test, y_pred_test),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, in order to assist with `over-fitting` we will make use of \n",
    "## `Cross Validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cross-validation is a technique for evaluating the performance of machine learning models and tuning their hyperparameters. It is important with regression models because it helps to prevent overfitting and provides a more reliable estimate of the model's performance on new data.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-parameters\n",
    "params = {\n",
    "    \"randomforestregressor__n_estimators\": range(25, 100, 25),\n",
    "    \"randomforestregressor__max_depth\": range(10, 50, 10)\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth\n",
    "[i for i in range(10, 50, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "[j for j in range(25, 100, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1)\n",
    "cv_results = pd.DataFrame(model.cv_results_)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the train data\n",
    "y_pred_training = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Compute MAE\n",
    "print(\"Training MAE:\", round(mean_absolute_error(y_train, y_pred_training),4))\n",
    "print(\"Test data MAE:\", round(mean_absolute_error(y_test, y_pred_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better model, thanks to `Cross-Validation`. We can proceed with `communicating our results`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1bb097269b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    " \n",
    "# Define the layout of the app with styling\n",
    "app.layout = html.Div(\n",
    "    style={'font-family': 'Arial, sans-serif', 'max-width': '600px', 'margin': 'auto',\n",
    "           'background-image': 'url(\"https://st2.depositphotos.com/2171279/8108/i/450/depositphotos_81089654-stock-photo-abstract-defocused-blurred-background-blur.jpg\")',  # path to your image file\n",
    "           'background-size': 'cover',\n",
    "           'background-position': 'center',\n",
    "           'background-repeat': 'no-repeat',\n",
    "           'padding': '20px',\n",
    "           'border': '1px solid grey',\n",
    "           'background-color': 'rgba(211, 211, 211, 0.5)'},  # Adding background color with transparency\n",
    "    children=[\n",
    "        html.H1(\"House Price Prediction\", style={'text-align': 'center'}),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"Number of Bedrooms\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='bedrooms', type='number', value=3, min=1, max=10, step=1),\n",
    "            ],\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"Number of Bathrooms\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='bathrooms', type='number', value=2, min=1, max=10, step=0.5),\n",
    "            ],\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"Square Footage of Living Area\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='sqft_living', type='number', value=1500, min=500, max=10000, step=50),\n",
    "            ],\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"Number of Floors\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='floors', type='number', value=1, min=1, max=5, step=0.5),\n",
    "            ],\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"Waterfront (1 if yes, 0 if no)\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='waterfront', type='number', value=0, min=0, max=1, step=1),\n",
    "            ],\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={'margin-bottom': '10px', 'display': 'flex', 'flex-direction': 'row', 'justify-content': 'space-between'},\n",
    "            children=[\n",
    "                html.Label(\"View (0 to 4)\", style={'font-weight': 'bold'}),\n",
    "                dcc.Input(id='view', type='number', value=0, min=0, max=4, step=1),\n",
    "            ],\n",
    "        ),\n",
    "        html.Button('Predict Price', id='predict-button', n_clicks=0, style={'margin-top': '10px'}),\n",
    "        html.Div(id='output-container-button', children='Enter values and click predict', style={'margin-top': '10px'}),\n",
    "    ]\n",
    ")\n",
    " \n",
    "# Define callback to update output\n",
    "@app.callback(\n",
    "    Output('output-container-button', 'children'),\n",
    "    [Input('predict-button', 'n_clicks')],\n",
    "    [dash.dependencies.State('bedrooms', 'value'),\n",
    "     dash.dependencies.State('bathrooms', 'value'),\n",
    "     dash.dependencies.State('sqft_living', 'value'),\n",
    "     dash.dependencies.State('floors', 'value'),\n",
    "     dash.dependencies.State('waterfront', 'value'),\n",
    "     dash.dependencies.State('view', 'value')])\n",
    "def update_output(n_clicks, bedrooms, bathrooms, sqft_living, floors, waterfront, view):\n",
    "    if n_clicks > 0:\n",
    "        input_data = pd.DataFrame({\n",
    "            'bedrooms': [bedrooms],\n",
    "            'bathrooms': [bathrooms],\n",
    "            'sqft_living': [sqft_living],\n",
    "            'floors': [floors],\n",
    "            'waterfront': [waterfront],\n",
    "            'view': [view],\n",
    "            'bedrooms_to_bathrooms_ratio': [bedrooms / bathrooms],\n",
    "            'price_per_sqft': [0],  # Replace NaN with a suitable value\n",
    "            'bedrooms_bathrooms_interaction': [bedrooms * bathrooms]\n",
    "        })\n",
    "        predicted_price = rf_reg.predict(input_data)[0]\n",
    "        return html.Div(f\"Predicted Price: ${predicted_price:,.2f}\", style={'font-weight': 'bold' })\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Link\n",
    "\n",
    "https://github.com/UZRashid/MLG382_Project2.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ed918a95895805da7d7508b9e57d0422e19f4a7e519d983f14e3e1eba5934af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
